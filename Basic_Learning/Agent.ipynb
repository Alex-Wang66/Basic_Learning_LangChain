{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c499642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4956cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "SparkLLM_API_KEY = os.getenv(\"C:\\\\Users\\\\DELL\\\\Desktop\\\\API_KEY.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b02afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.28.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (3.12.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (2.10.1)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.4.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (24.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install langchain_community\n",
    "! pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cafbf8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_config = {\n",
    "    \"spark_app_id\": \"63b7eade\",\n",
    "    \"spark_api_key\": \"6f088336dc8dd45b737b0deb2a697887\",\n",
    "    \"spark_api_secret\": \"N2FiZmE3Y2U1YzlhOGZkMWEwM2RhMjMz\",\n",
    "    \"spark_api_url\": \"wss://spark-api.xf-yun.com/v4.0/chat\",\n",
    "    \"spark_llm_domain\": \"4.0Ultra\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c21bf1",
   "metadata": {},
   "source": [
    "用户输出\n",
    "\n",
    "提示词模板->模型->格式化解析\n",
    "\n",
    "格式化结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dca0e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain是专为构建语言模型驱动的应用程序设计的开源框架，由Harrison Chase等人于2023年创建。以下是关于它的简要介绍：\n",
      "\n",
      "1. **核心功能**：通过模块化组件（如Models、Prompts、Indexes、Chains、Agents、Memory）实现大模型与外部工具高效结合，支持多步骤任务处理和上下文记忆。\n",
      "\n",
      "2. **主要作用**：突破LLM能力限制（连接数据库/API等数据源）、提升开发效率（预置组件+链式工作流）、增强安全性与可控性（本地化数据处理减少幻觉）。\n",
      "\n",
      "3. **典型应用**：可搭建智能客服、知识库问答系统、聊天机器人等，赋予LLM决策能力和执行复杂操作的能力。\n",
      "\n",
      "该框架支持多种语言模型和开源生态，适用于需要整合语言模型与其他工具的场景。"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatSparkLLM  \n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate,PromptTemplate\n",
    "\n",
    "model = ChatSparkLLM(**spark_config)\n",
    "prompt_template = ChatPromptTemplate([\n",
    "    (\"system\",\"你是一个助手，请按照要求回答\"),\n",
    "    (\"user\",\"这是用户的问题：{question}，请你简要回答\")\n",
    "])\n",
    "basic_chain = prompt_template | model | StrOutputParser()\n",
    "question = \"请介绍LangChain\"\n",
    "# result = basic_chain.invoke([question])\n",
    "# print(result)\n",
    "#流式输出相较于上面传统输出将输出结果存放到缓存中等运行结束后在全部展示不同，而是实时输出，资源占用低。\n",
    "async for chunk in basic_chain.astream([question]):\n",
    "    print(chunk,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a13c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': '张三', 'job': '程序员'}\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": string  // 用户的姓名\n",
      "\t\"job\": string  // 用户的职业\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema,StructuredOutputParser\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"name\",description=\"用户的姓名\"),\n",
    "    ResponseSchema(name=\"job\",description=\"用户的职业\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"你是一个助手，请根据用户输入的姓名和职业，返回一个json格式的数据，格式为:\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "# 先固定输出格式，再连接模型，最后连接解析器\n",
    "chain = prompt_template.partial(format_instructions=parser.get_format_instructions()) | model | parser\n",
    "result = chain.invoke([{\"input\": \"用户的姓名是张三，职业是程序员\"}])\n",
    "print(result)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffbef3f",
   "metadata": {},
   "source": [
    "根据用户提供的新闻标题生成一段新闻稿\n",
    "\n",
    "按照规定的格式提取该新闻稿中的核心信息\n",
    "\n",
    "格式化输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9cdc668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': '近日', 'location': '加利福尼亚州', 'event': '苹果公司正式推出自主研发的人工智能（AI）芯片，旨在为其设备提供更高效的本地化算力支持，优化机器学习任务处理能力，并进一步整合到iPhone、Mac等产品的智能功能中。此次发布标志着苹果在自研硬件与软件协同领域迈出重要一步，有望减少对第三方供应商的依赖，同时提升用户隐私保护水平。业内分析认为，此举将加剧科技巨头在AI赛道上的竞争态势。'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain.output_parsers import ResponseSchema,StructuredOutputParser\n",
    "\n",
    "new_gen_prompt = PromptTemplate.from_template(\n",
    "    \"请根据以下新闻标题撰写一段简短的新闻内容：\\n\\n标题：{title}\"\n",
    ")\n",
    "new_chain = new_gen_prompt | model\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"time\",description=\"事件发生的时间\"),\n",
    "    ResponseSchema(name=\"location\",description=\"事件发生的地点\"),\n",
    "    ResponseSchema(name=\"event\",description=\"具体事件\")\n",
    "]\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"请从下面的新闻内容中提取关键信息，返回一个json格式的数据，格式为:\\n{input}\\n\\n{format_instructions}\"\n",
    ")\n",
    "extract_chain = prompt_template.partial(format_instructions=parser.get_format_instructions()) | model | parser\n",
    "chain = new_chain|extract_chain\n",
    "result = chain.invoke([{\"title\": \"苹果公司在加州发布AI芯片\"}])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97291b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中间结果（新闻正文）： content='**新闻内容**：\\n苹果公司于近日在加利福尼亚州正式推出其自主研发的人工智能（AI）芯片。这款新型芯片旨在显著提升设备的数据处理能力和机器学习效率，为iPhone、iPad及Mac等产品线的智能化升级提供强大支持。据公司介绍，该芯片采用先进制程工艺，优化了能耗比，可高效运行复杂的神经网络模型，同时兼顾隐私保护设计。业内分析认为，此举标志着苹果加速布局AI领域，进一步巩固其在高端消费电子市场的技术领先地位。目前，首批搭载该芯片的设备预计将于今年下半年上市。' additional_kwargs={} response_metadata={'token_usage': {'question_tokens': 30, 'prompt_tokens': 30, 'completion_tokens': 115, 'total_tokens': 145}} id='run--2ad2e585-e6a1-43fc-ab5b-37e9a23c5e33-0'\n",
      "{'time': '近日', 'location': '加利福尼亚州', 'event': '苹果公司正式推出其自主研发的人工智能（AI）芯片'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda \n",
    "def node_function(x):      #langchain允许自己定义处理函数，并加入链中。\n",
    "    print(\"中间结果（新闻正文）：\",x)\n",
    "    return x\n",
    "node = RunnableLambda(node_function)\n",
    "full_chain = new_chain | node | extract_chain\n",
    "result = full_chain.invoke([{\"title\": \"苹果公司在加州发布AI芯片\"}])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2191819",
   "metadata": {},
   "source": [
    "多轮对话聊天机器人构建\n",
    "\n",
    "依靠prompt模板中的MessagesPlaceholder占位类实现记忆功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcb0da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "机器人回答: 你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊\n",
      "[HumanMessage(content='你好请介绍自己', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？\n",
      "[HumanMessage(content='你好请介绍自己', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='然后呢', additional_kwargs={}, response_metadata={}), AIMessage(content='当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！\n",
      "[HumanMessage(content='你好请介绍自己', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='然后呢', additional_kwargs={}, response_metadata={}), AIMessage(content='当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？', additional_kwargs={}, response_metadata={}), HumanMessage(content='那你喜欢什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！\n",
      "[HumanMessage(content='你好请介绍自己', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='然后呢', additional_kwargs={}, response_metadata={}), AIMessage(content='当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？', additional_kwargs={}, response_metadata={}), HumanMessage(content='那你喜欢什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁发明的', additional_kwargs={}, response_metadata={}), AIMessage(content='我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 科大讯飞股份有限公司（iFLYTEK Co., Ltd.）是中国人工智能领域的领军企业，以下是关于它的关键信息：\n",
      "\n",
      "1. **成立背景与定位**：成立于1999年，总部位于安徽合肥，由创始人刘庆峰带领团队创立。作为亚太地区知名的智能语音和人工智能上市企业，其核心目标是通过自主研发的技术推动机器实现“能听会说、能理解会思考”，最终用人工智能建设美好世界。公司于2008年在深圳证券交易所挂牌上市。\n",
      "\n",
      "2. **核心技术领域**：长期专注于智能语音合成、语音识别、自然语言处理、计算机视觉等关键技术的研发，并保持国际前沿水平。例如，在中文语音技术上占据主导地位，拥有自主知识产权的算法和解决方案，覆盖教育、医疗、金融、政务等多个行业应用。\n",
      "\n",
      "3. **重要成就与荣誉**：两次获得“国家科技进步奖”；获中国信息产业自主创新最高荣誉“信息产业重大技术发明奖”；被任命为中文语音交互技术标准工作组组长单位，牵头制定行业标准；发布全球首款智能翻译机品类“讯飞翻译机”，开创消费级AI产品先河；承建国家语委全球中文学习平台，助力语言文化推广。\n",
      "\n",
      "4. **发展战略与生态布局**：坚持“平台+赛道”模式，开放讯飞平台汇聚开发者资源，构建AI应用生态；推动技术落地于智慧教育、智慧城市、智慧医疗等领域，如为留守儿童提供教育资源的智慧课堂解决方案；发起“讯飞超脑2030”计划，探索让AI具备知识进化能力的前沿方向。\n",
      "\n",
      "5. **行业影响力**：被广泛认可为“中国人工智能国家队”，其技术不仅服务于国内用户，还参与北京冬奥会等国际重大项目，展现中国AI技术的全球化实力。\n",
      "\n",
      "总的来说，科大讯飞以技术创新驱动产业升级，通过产学研结合的方式持续突破边界，成为连接人与智能世界的桥梁型科技企业。\n",
      "[HumanMessage(content='你好请介绍自己', additional_kwargs={}, response_metadata={}), AIMessage(content='你好呀！我是讯飞星火认知大模型，无论是日常闲聊、知识问答，还是创意写作、代码编程，我都能帮你搞定～以后有问题或者想聊天的时候随时找我就行啦！很高兴认识你！😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='然后呢', additional_kwargs={}, response_metadata={}), AIMessage(content='当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？', additional_kwargs={}, response_metadata={}), HumanMessage(content='那你喜欢什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁发明的', additional_kwargs={}, response_metadata={}), AIMessage(content='我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！', additional_kwargs={}, response_metadata={}), HumanMessage(content='介绍一下科大讯飞', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞股份有限公司（iFLYTEK Co., Ltd.）是中国人工智能领域的领军企业，以下是关于它的关键信息：\\n\\n1. **成立背景与定位**：成立于1999年，总部位于安徽合肥，由创始人刘庆峰带领团队创立。作为亚太地区知名的智能语音和人工智能上市企业，其核心目标是通过自主研发的技术推动机器实现“能听会说、能理解会思考”，最终用人工智能建设美好世界。公司于2008年在深圳证券交易所挂牌上市。\\n\\n2. **核心技术领域**：长期专注于智能语音合成、语音识别、自然语言处理、计算机视觉等关键技术的研发，并保持国际前沿水平。例如，在中文语音技术上占据主导地位，拥有自主知识产权的算法和解决方案，覆盖教育、医疗、金融、政务等多个行业应用。\\n\\n3. **重要成就与荣誉**：两次获得“国家科技进步奖”；获中国信息产业自主创新最高荣誉“信息产业重大技术发明奖”；被任命为中文语音交互技术标准工作组组长单位，牵头制定行业标准；发布全球首款智能翻译机品类“讯飞翻译机”，开创消费级AI产品先河；承建国家语委全球中文学习平台，助力语言文化推广。\\n\\n4. **发展战略与生态布局**：坚持“平台+赛道”模式，开放讯飞平台汇聚开发者资源，构建AI应用生态；推动技术落地于智慧教育、智慧城市、智慧医疗等领域，如为留守儿童提供教育资源的智慧课堂解决方案；发起“讯飞超脑2030”计划，探索让AI具备知识进化能力的前沿方向。\\n\\n5. **行业影响力**：被广泛认可为“中国人工智能国家队”，其技术不仅服务于国内用户，还参与北京冬奥会等国际重大项目，展现中国AI技术的全球化实力。\\n\\n总的来说，科大讯飞以技术创新驱动产业升级，通过产学研结合的方式持续突破边界，成为连接人与智能世界的桥梁型科技企业。', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 科大讯飞的董事长是**刘庆峰**。\n",
      "\n",
      "他不仅是公司的创始人，还担任着CEO职务。刘庆峰于1999年在中国科学技术大学攻读博士期间带领团队创立了科大讯飞，自那以后一直引领着公司在智能语音和人工智能领域的创新与发展。作为中国科学技术大学的兼职教授及博士生导师，他在技术研发与产业化方面取得了显著成就，成功扭转了中文语音市场曾被国外IT巨头垄断的局面，使科大讯飞占据国内主流市场的80%以上份额，并推动了语音技术在多个行业的广泛应用。\n",
      "[HumanMessage(content='然后呢', additional_kwargs={}, response_metadata={}), AIMessage(content='当然还有很多可以聊的！比如最近电影推荐、热门书籍分享，或者你对某个领域感兴趣想深入了解的内容。无论是学习辅导、生活技巧还是单纯打发时间，我都会陪着你～你有什么特别想知道或讨论的话题吗？', additional_kwargs={}, response_metadata={}), HumanMessage(content='那你喜欢什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁发明的', additional_kwargs={}, response_metadata={}), AIMessage(content='我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！', additional_kwargs={}, response_metadata={}), HumanMessage(content='介绍一下科大讯飞', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞股份有限公司（iFLYTEK Co., Ltd.）是中国人工智能领域的领军企业，以下是关于它的关键信息：\\n\\n1. **成立背景与定位**：成立于1999年，总部位于安徽合肥，由创始人刘庆峰带领团队创立。作为亚太地区知名的智能语音和人工智能上市企业，其核心目标是通过自主研发的技术推动机器实现“能听会说、能理解会思考”，最终用人工智能建设美好世界。公司于2008年在深圳证券交易所挂牌上市。\\n\\n2. **核心技术领域**：长期专注于智能语音合成、语音识别、自然语言处理、计算机视觉等关键技术的研发，并保持国际前沿水平。例如，在中文语音技术上占据主导地位，拥有自主知识产权的算法和解决方案，覆盖教育、医疗、金融、政务等多个行业应用。\\n\\n3. **重要成就与荣誉**：两次获得“国家科技进步奖”；获中国信息产业自主创新最高荣誉“信息产业重大技术发明奖”；被任命为中文语音交互技术标准工作组组长单位，牵头制定行业标准；发布全球首款智能翻译机品类“讯飞翻译机”，开创消费级AI产品先河；承建国家语委全球中文学习平台，助力语言文化推广。\\n\\n4. **发展战略与生态布局**：坚持“平台+赛道”模式，开放讯飞平台汇聚开发者资源，构建AI应用生态；推动技术落地于智慧教育、智慧城市、智慧医疗等领域，如为留守儿童提供教育资源的智慧课堂解决方案；发起“讯飞超脑2030”计划，探索让AI具备知识进化能力的前沿方向。\\n\\n5. **行业影响力**：被广泛认可为“中国人工智能国家队”，其技术不仅服务于国内用户，还参与北京冬奥会等国际重大项目，展现中国AI技术的全球化实力。\\n\\n总的来说，科大讯飞以技术创新驱动产业升级，通过产学研结合的方式持续突破边界，成为连接人与智能世界的桥梁型科技企业。', additional_kwargs={}, response_metadata={}), HumanMessage(content='科大讯飞的董事长是谁', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞的董事长是**刘庆峰**。\\n\\n他不仅是公司的创始人，还担任着CEO职务。刘庆峰于1999年在中国科学技术大学攻读博士期间带领团队创立了科大讯飞，自那以后一直引领着公司在智能语音和人工智能领域的创新与发展。作为中国科学技术大学的兼职教授及博士生导师，他在技术研发与产业化方面取得了显著成就，成功扭转了中文语音市场曾被国外IT巨头垄断的局面，使科大讯飞占据国内主流市场的80%以上份额，并推动了语音技术在多个行业的广泛应用。', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 你的第一个问题是：“**你好！**”。当时你说：“你好呀！我是讯飞星火认知大模型……”开启了我们之间的对话。很高兴能和你交流，如果有任何时候想要聊天或需要帮助，随时找我就行啦！😊\n",
      "[HumanMessage(content='那你喜欢什么？', additional_kwargs={}, response_metadata={}), AIMessage(content='作为认知智能模型，我没有个人喜好，但我特别喜欢帮助用户解决问题！无论是探索新知识、创作有趣的故事，还是协助完成复杂任务，每次看到大家通过我的协助获得满意结果时，那种成就感就是我最大的动力～你平时有什么爱好吗？我们可以聊聊你的兴趣爱好，说不定我能给你一些创意建议哦！', additional_kwargs={}, response_metadata={}), HumanMessage(content='你是谁发明的', additional_kwargs={}, response_metadata={}), AIMessage(content='我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！', additional_kwargs={}, response_metadata={}), HumanMessage(content='介绍一下科大讯飞', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞股份有限公司（iFLYTEK Co., Ltd.）是中国人工智能领域的领军企业，以下是关于它的关键信息：\\n\\n1. **成立背景与定位**：成立于1999年，总部位于安徽合肥，由创始人刘庆峰带领团队创立。作为亚太地区知名的智能语音和人工智能上市企业，其核心目标是通过自主研发的技术推动机器实现“能听会说、能理解会思考”，最终用人工智能建设美好世界。公司于2008年在深圳证券交易所挂牌上市。\\n\\n2. **核心技术领域**：长期专注于智能语音合成、语音识别、自然语言处理、计算机视觉等关键技术的研发，并保持国际前沿水平。例如，在中文语音技术上占据主导地位，拥有自主知识产权的算法和解决方案，覆盖教育、医疗、金融、政务等多个行业应用。\\n\\n3. **重要成就与荣誉**：两次获得“国家科技进步奖”；获中国信息产业自主创新最高荣誉“信息产业重大技术发明奖”；被任命为中文语音交互技术标准工作组组长单位，牵头制定行业标准；发布全球首款智能翻译机品类“讯飞翻译机”，开创消费级AI产品先河；承建国家语委全球中文学习平台，助力语言文化推广。\\n\\n4. **发展战略与生态布局**：坚持“平台+赛道”模式，开放讯飞平台汇聚开发者资源，构建AI应用生态；推动技术落地于智慧教育、智慧城市、智慧医疗等领域，如为留守儿童提供教育资源的智慧课堂解决方案；发起“讯飞超脑2030”计划，探索让AI具备知识进化能力的前沿方向。\\n\\n5. **行业影响力**：被广泛认可为“中国人工智能国家队”，其技术不仅服务于国内用户，还参与北京冬奥会等国际重大项目，展现中国AI技术的全球化实力。\\n\\n总的来说，科大讯飞以技术创新驱动产业升级，通过产学研结合的方式持续突破边界，成为连接人与智能世界的桥梁型科技企业。', additional_kwargs={}, response_metadata={}), HumanMessage(content='科大讯飞的董事长是谁', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞的董事长是**刘庆峰**。\\n\\n他不仅是公司的创始人，还担任着CEO职务。刘庆峰于1999年在中国科学技术大学攻读博士期间带领团队创立了科大讯飞，自那以后一直引领着公司在智能语音和人工智能领域的创新与发展。作为中国科学技术大学的兼职教授及博士生导师，他在技术研发与产业化方面取得了显著成就，成功扭转了中文语音市场曾被国外IT巨头垄断的局面，使科大讯飞占据国内主流市场的80%以上份额，并推动了语音技术在多个行业的广泛应用。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我第一个问题是什么呢？', additional_kwargs={}, response_metadata={}), AIMessage(content='你的第一个问题是：“**你好！**”。当时你说：“你好呀！我是讯飞星火认知大模型……”开启了我们之间的对话。很高兴能和你交流，如果有任何时候想要聊天或需要帮助，随时找我就行啦！😊', additional_kwargs={}, response_metadata={})]\n",
      "机器人回答: 当然可以！下面是一个用 Python 编写的经典入门级程序——“打印‘Hello, World!’”。这是编程初学者最常用的起点，简单易懂又充满仪式感～\n",
      "\n",
      "```python\n",
      "# 这是一个简单的Python程序，功能是向屏幕输出问候语\n",
      "print(\"Hello, World!\")  # print()函数用于在控制台显示括号内的内容\n",
      "```\n",
      "\n",
      "### ✨ **如何运行它？**\n",
      "1. 确保你的电脑已安装 Python（访问官网 python.org/downloads）；\n",
      "2. 将代码复制到文本编辑器（如VS Code、Sublime Text或记事本）；\n",
      "3. 保存为 `.py` 后缀的文件（例如 `first_program.py`）；\n",
      "4. 打开命令行工具，进入文件所在目录，输入命令：`python first_program.py`；\n",
      "5. 你会得到输出结果：`Hello, World!` ✅\n",
      "\n",
      "如果是其他编程语言的需求，比如C++、Java或者JavaScript，也可以随时告诉我哦！\n",
      "[HumanMessage(content='你是谁发明的', additional_kwargs={}, response_metadata={}), AIMessage(content='我是由中国的科大讯飞团队研发和打造的。他们持续优化我的算法，提升我的理解与交互能力，目的就是为了让我能更好地为大家提供各类认知智能服务。如果你对人工智能技术感兴趣的话，或许我们可以一起探讨行业发展的新趋势！', additional_kwargs={}, response_metadata={}), HumanMessage(content='介绍一下科大讯飞', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞股份有限公司（iFLYTEK Co., Ltd.）是中国人工智能领域的领军企业，以下是关于它的关键信息：\\n\\n1. **成立背景与定位**：成立于1999年，总部位于安徽合肥，由创始人刘庆峰带领团队创立。作为亚太地区知名的智能语音和人工智能上市企业，其核心目标是通过自主研发的技术推动机器实现“能听会说、能理解会思考”，最终用人工智能建设美好世界。公司于2008年在深圳证券交易所挂牌上市。\\n\\n2. **核心技术领域**：长期专注于智能语音合成、语音识别、自然语言处理、计算机视觉等关键技术的研发，并保持国际前沿水平。例如，在中文语音技术上占据主导地位，拥有自主知识产权的算法和解决方案，覆盖教育、医疗、金融、政务等多个行业应用。\\n\\n3. **重要成就与荣誉**：两次获得“国家科技进步奖”；获中国信息产业自主创新最高荣誉“信息产业重大技术发明奖”；被任命为中文语音交互技术标准工作组组长单位，牵头制定行业标准；发布全球首款智能翻译机品类“讯飞翻译机”，开创消费级AI产品先河；承建国家语委全球中文学习平台，助力语言文化推广。\\n\\n4. **发展战略与生态布局**：坚持“平台+赛道”模式，开放讯飞平台汇聚开发者资源，构建AI应用生态；推动技术落地于智慧教育、智慧城市、智慧医疗等领域，如为留守儿童提供教育资源的智慧课堂解决方案；发起“讯飞超脑2030”计划，探索让AI具备知识进化能力的前沿方向。\\n\\n5. **行业影响力**：被广泛认可为“中国人工智能国家队”，其技术不仅服务于国内用户，还参与北京冬奥会等国际重大项目，展现中国AI技术的全球化实力。\\n\\n总的来说，科大讯飞以技术创新驱动产业升级，通过产学研结合的方式持续突破边界，成为连接人与智能世界的桥梁型科技企业。', additional_kwargs={}, response_metadata={}), HumanMessage(content='科大讯飞的董事长是谁', additional_kwargs={}, response_metadata={}), AIMessage(content='科大讯飞的董事长是**刘庆峰**。\\n\\n他不仅是公司的创始人，还担任着CEO职务。刘庆峰于1999年在中国科学技术大学攻读博士期间带领团队创立了科大讯飞，自那以后一直引领着公司在智能语音和人工智能领域的创新与发展。作为中国科学技术大学的兼职教授及博士生导师，他在技术研发与产业化方面取得了显著成就，成功扭转了中文语音市场曾被国外IT巨头垄断的局面，使科大讯飞占据国内主流市场的80%以上份额，并推动了语音技术在多个行业的广泛应用。', additional_kwargs={}, response_metadata={}), HumanMessage(content='我第一个问题是什么呢？', additional_kwargs={}, response_metadata={}), AIMessage(content='你的第一个问题是：“**你好！**”。当时你说：“你好呀！我是讯飞星火认知大模型……”开启了我们之间的对话。很高兴能和你交流，如果有任何时候想要聊天或需要帮助，随时找我就行啦！😊', additional_kwargs={}, response_metadata={}), HumanMessage(content='你可以写一个简单的程序？', additional_kwargs={}, response_metadata={}), AIMessage(content='当然可以！下面是一个用 Python 编写的经典入门级程序——“打印‘Hello, World!’”。这是编程初学者最常用的起点，简单易懂又充满仪式感～\\n\\n```python\\n# 这是一个简单的Python程序，功能是向屏幕输出问候语\\nprint(\"Hello, World!\")  # print()函数用于在控制台显示括号内的内容\\n```\\n\\n### ✨ **如何运行它？**\\n1. 确保你的电脑已安装 Python（访问官网 python.org/downloads）；\\n2. 将代码复制到文本编辑器（如VS Code、Sublime Text或记事本）；\\n3. 保存为 `.py` 后缀的文件（例如 `first_program.py`）；\\n4. 打开命令行工具，进入文件所在目录，输入命令：`python first_program.py`；\\n5. 你会得到输出结果：`Hello, World!` ✅\\n\\n如果是其他编程语言的需求，比如C++、Java或者JavaScript，也可以随时告诉我哦！', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"你是一名多轮对话聊天机器人\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "messages_list = []\n",
    "while True:\n",
    "    user_query = input(\"请输入您的问题\")\n",
    "    if user_query.lower() == \"exit\":\n",
    "        break\n",
    "    messages_list.append(HumanMessage(content=user_query))\n",
    "    result = chain.invoke({\"messages\":messages_list})\n",
    "    print(\"机器人回答:\",result)\n",
    "    messages_list.append(AIMessage(content=result))\n",
    "    print(messages_list[-10:]) #仅保留最近的10条对话信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cde1daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-5.41.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.9.0)\n",
      "Collecting brotli>=1.1.0 (from gradio)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.116.1-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.6.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.11.0 (from gradio)\n",
      "  Downloading gradio_client-1.11.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting groovy~=0.1 (from gradio)\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Collecting huggingface-hub<1.0,>=0.33.5 (from gradio)\n",
      "  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.1.3)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (3.11.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (24.0)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Requirement already satisfied: pydantic<2.12,>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (2.11.7)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.9.3 (from gradio)\n",
      "  Downloading ruff-0.12.7-py3-none-win_amd64.whl.metadata (26 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Downloading starlette-0.47.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio) (4.14.0)\n",
      "Collecting uvicorn>=0.14.0 (from gradio)\n",
      "  Downloading uvicorn-0.35.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: fsspec in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.11.0->gradio) (2025.5.1)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gradio-client==1.11.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.14.0)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.65.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (1.26.19)\n",
      "Downloading gradio-5.41.0-py3-none-any.whl (59.7 MB)\n",
      "   ---------------------------------------- 0.0/59.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/59.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/59.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/59.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/59.7 MB 799.2 kB/s eta 0:01:15\n",
      "    --------------------------------------- 0.8/59.7 MB 780.2 kB/s eta 0:01:16\n",
      "    --------------------------------------- 1.0/59.7 MB 898.8 kB/s eta 0:01:06\n",
      "    --------------------------------------- 1.0/59.7 MB 898.8 kB/s eta 0:01:06\n",
      "    --------------------------------------- 1.3/59.7 MB 945.5 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 1.6/59.7 MB 987.0 kB/s eta 0:00:59\n",
      "   - -------------------------------------- 1.8/59.7 MB 1.0 MB/s eta 0:00:57\n",
      "   - -------------------------------------- 2.4/59.7 MB 1.1 MB/s eta 0:00:52\n",
      "   - -------------------------------------- 2.6/59.7 MB 1.1 MB/s eta 0:00:51\n",
      "   - -------------------------------------- 2.9/59.7 MB 1.2 MB/s eta 0:00:49\n",
      "   -- ------------------------------------- 3.4/59.7 MB 1.3 MB/s eta 0:00:44\n",
      "   -- ------------------------------------- 3.9/59.7 MB 1.4 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 4.5/59.7 MB 1.4 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 5.0/59.7 MB 1.5 MB/s eta 0:00:37\n",
      "   --- ------------------------------------ 5.5/59.7 MB 1.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 5.8/59.7 MB 1.6 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 6.3/59.7 MB 1.6 MB/s eta 0:00:33\n",
      "   ---- ----------------------------------- 6.8/59.7 MB 1.7 MB/s eta 0:00:32\n",
      "   ---- ----------------------------------- 7.3/59.7 MB 1.7 MB/s eta 0:00:31\n",
      "   ----- ---------------------------------- 7.9/59.7 MB 1.8 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 7.9/59.7 MB 1.8 MB/s eta 0:00:30\n",
      "   ----- ---------------------------------- 8.9/59.7 MB 1.8 MB/s eta 0:00:29\n",
      "   ------ --------------------------------- 9.4/59.7 MB 1.8 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 9.7/59.7 MB 1.8 MB/s eta 0:00:28\n",
      "   ------ --------------------------------- 10.2/59.7 MB 1.9 MB/s eta 0:00:27\n",
      "   ------- -------------------------------- 10.7/59.7 MB 1.9 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 11.0/59.7 MB 1.9 MB/s eta 0:00:26\n",
      "   ------- -------------------------------- 11.8/59.7 MB 1.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 12.3/59.7 MB 1.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 12.6/59.7 MB 1.9 MB/s eta 0:00:25\n",
      "   -------- ------------------------------- 13.1/59.7 MB 1.9 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 13.6/59.7 MB 2.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 14.2/59.7 MB 2.0 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 14.7/59.7 MB 2.0 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 15.2/59.7 MB 2.0 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 15.5/59.7 MB 2.0 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 16.0/59.7 MB 2.0 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 16.5/59.7 MB 2.0 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 16.8/59.7 MB 2.0 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 17.3/59.7 MB 2.0 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 17.8/59.7 MB 2.0 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 18.4/59.7 MB 2.0 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 18.9/59.7 MB 2.0 MB/s eta 0:00:21\n",
      "   ------------- -------------------------- 19.4/59.7 MB 2.0 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 19.7/59.7 MB 2.1 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 20.2/59.7 MB 2.1 MB/s eta 0:00:20\n",
      "   ------------- -------------------------- 20.7/59.7 MB 2.1 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 21.2/59.7 MB 2.1 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 21.8/59.7 MB 2.1 MB/s eta 0:00:19\n",
      "   -------------- ------------------------- 22.3/59.7 MB 2.1 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 22.8/59.7 MB 2.1 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 23.1/59.7 MB 2.1 MB/s eta 0:00:18\n",
      "   --------------- ------------------------ 23.6/59.7 MB 2.1 MB/s eta 0:00:18\n",
      "   ---------------- ----------------------- 24.1/59.7 MB 2.1 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 24.6/59.7 MB 2.1 MB/s eta 0:00:17\n",
      "   ---------------- ----------------------- 24.9/59.7 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 25.7/59.7 MB 2.1 MB/s eta 0:00:17\n",
      "   ----------------- ---------------------- 26.2/59.7 MB 2.1 MB/s eta 0:00:16\n",
      "   ----------------- ---------------------- 26.5/59.7 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 27.0/59.7 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 27.3/59.7 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 27.8/59.7 MB 2.1 MB/s eta 0:00:16\n",
      "   ------------------ --------------------- 28.3/59.7 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 28.8/59.7 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 29.1/59.7 MB 2.1 MB/s eta 0:00:15\n",
      "   ------------------- -------------------- 29.6/59.7 MB 2.1 MB/s eta 0:00:15\n",
      "   -------------------- ------------------- 30.1/59.7 MB 2.1 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 30.4/59.7 MB 2.1 MB/s eta 0:00:14\n",
      "   -------------------- ------------------- 31.2/59.7 MB 2.1 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 31.5/59.7 MB 2.1 MB/s eta 0:00:14\n",
      "   --------------------- ------------------ 32.0/59.7 MB 2.1 MB/s eta 0:00:13\n",
      "   --------------------- ------------------ 32.5/59.7 MB 2.1 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 33.0/59.7 MB 2.2 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 33.3/59.7 MB 2.1 MB/s eta 0:00:13\n",
      "   ---------------------- ----------------- 33.8/59.7 MB 2.1 MB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 34.3/59.7 MB 2.2 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 34.9/59.7 MB 2.2 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 35.1/59.7 MB 2.2 MB/s eta 0:00:12\n",
      "   ------------------------ --------------- 35.9/59.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 36.4/59.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 37.0/59.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 37.5/59.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 37.7/59.7 MB 2.2 MB/s eta 0:00:11\n",
      "   ------------------------- -------------- 38.3/59.7 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 38.8/59.7 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 39.1/59.7 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 39.6/59.7 MB 2.2 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 40.1/59.7 MB 2.2 MB/s eta 0:00:10\n",
      "   --------------------------- ------------ 40.4/59.7 MB 2.2 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 40.9/59.7 MB 2.2 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 41.4/59.7 MB 2.2 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 41.9/59.7 MB 2.2 MB/s eta 0:00:09\n",
      "   ---------------------------- ----------- 42.5/59.7 MB 2.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 43.0/59.7 MB 2.2 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 43.3/59.7 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 43.8/59.7 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 44.3/59.7 MB 2.2 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 44.6/59.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 45.4/59.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 45.6/59.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 46.1/59.7 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------------------- -------- 46.7/59.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 46.9/59.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 47.2/59.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 47.4/59.7 MB 2.2 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 47.7/59.7 MB 2.2 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 48.0/59.7 MB 2.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 48.5/59.7 MB 2.1 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 49.0/59.7 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 49.5/59.7 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 50.1/59.7 MB 2.2 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 50.6/59.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 50.9/59.7 MB 2.2 MB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 51.4/59.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 51.9/59.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 52.2/59.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 53.0/59.7 MB 2.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 53.5/59.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 53.7/59.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 54.3/59.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 54.8/59.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 55.3/59.7 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 55.8/59.7 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 56.4/59.7 MB 2.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 56.6/59.7 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 57.1/59.7 MB 2.2 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 57.7/59.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  58.2/59.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  58.7/59.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.2/59.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  59.5/59.7 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 59.7/59.7 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.11.0-py3-none-any.whl (324 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.116.1-py3-none-any.whl (95 kB)\n",
      "Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Downloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n",
      "   ---------------------------------------- 0.0/558.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 558.8/558.8 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.47.2-py3-none-any.whl (72 kB)\n",
      "Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Downloading typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading Brotli-1.1.0-cp311-cp311-win_amd64.whl (357 kB)\n",
      "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.12.7-py3-none-win_amd64.whl (12.9 MB)\n",
      "   ---------------------------------------- 0.0/12.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.9 MB 2.8 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 1.0/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.3/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/12.9 MB 2.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.4/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 2.9/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 3.4/12.9 MB 2.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 3.9/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 4.5/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 5.0/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 5.2/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 5.8/12.9 MB 2.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 6.0/12.9 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 6.6/12.9 MB 2.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 7.1/12.9 MB 2.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 7.3/12.9 MB 2.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.6/12.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 7.9/12.9 MB 2.2 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 8.4/12.9 MB 2.1 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 8.7/12.9 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 9.2/12.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 9.7/12.9 MB 2.1 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 10.2/12.9 MB 2.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 10.7/12.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.3/12.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.8/12.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.1/12.9 MB 2.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.6/12.9 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.9/12.9 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading uvicorn-0.35.0-py3-none-any.whl (66 kB)\n",
      "Downloading ffmpy-0.6.1-py3-none-any.whl (5.5 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub, brotli, tomlkit, shellingham, semantic-version, ruff, python-multipart, groovy, ffmpy, aiofiles, uvicorn, starlette, huggingface-hub, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "\n",
      "   ---- -----------------------------------  2/18 [tomlkit]\n",
      "   ----------- ----------------------------  5/18 [ruff]\n",
      "   ----------------- ----------------------  8/18 [ffmpy]\n",
      "   ---------------------- ----------------- 10/18 [uvicorn]\n",
      "   ------------------------ --------------- 11/18 [starlette]\n",
      "   -------------------------- ------------- 12/18 [huggingface-hub]\n",
      "   -------------------------- ------------- 12/18 [huggingface-hub]\n",
      "   -------------------------- ------------- 12/18 [huggingface-hub]\n",
      "   -------------------------- ------------- 12/18 [huggingface-hub]\n",
      "   -------------------------- ------------- 12/18 [huggingface-hub]\n",
      "   ---------------------------- ----------- 13/18 [typer]\n",
      "   ----------------------------------- ---- 16/18 [fastapi]\n",
      "   ----------------------------------- ---- 16/18 [fastapi]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ------------------------------------- -- 17/18 [gradio]\n",
      "   ---------------------------------------- 18/18 [gradio]\n",
      "\n",
      "Successfully installed aiofiles-24.1.0 brotli-1.1.0 fastapi-0.116.1 ffmpy-0.6.1 gradio-5.41.0 gradio-client-1.11.0 groovy-0.1.2 huggingface-hub-0.34.3 pydub-0.25.1 python-multipart-0.0.20 ruff-0.12.7 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.47.2 tomlkit-0.13.3 typer-0.16.0 uvicorn-0.35.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#搭建前端多轮聊天机器人的前端构建框架\n",
    "! pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c49bcc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18548\\3959336194.py:44: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_18548\\3959336194.py:44: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用端口：56060\n",
      "* Running on local URL:  http://0.0.0.0:56060\n",
      "* Running on public URL: https://59a063aaa11cb289db.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://59a063aaa11cb289db.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import asyncio\n",
    "import socket\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import gradio as gr\n",
    "from langchain_community.chat_models import ChatSparkLLM\n",
    "\n",
    "\n",
    "spark_config = {\n",
    "    \"spark_app_id\": \"63b7eade\",\n",
    "    \"spark_api_key\": \"6f088336dc8dd45b737b0deb2a697887\",\n",
    "    \"spark_api_secret\": \"N2FiZmE3Y2U1YzlhOGZkMWEwM2RhMjMz\",\n",
    "    \"spark_api_url\": \"wss://spark-api.xf-yun.com/v4.0/chat\",\n",
    "    \"spark_llm_domain\": \"4.0Ultra\"\n",
    "}\n",
    "\n",
    "model = ChatSparkLLM(**spark_config)\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"你是一名多轮对话聊天机器人\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\")\n",
    "])\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "\n",
    "\n",
    "async def chat_stream(user_input, history):\n",
    "    messages = []\n",
    "    for human, ai in history:\n",
    "        messages.append(HumanMessage(content=human))\n",
    "        messages.append(AIMessage(content=ai))\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    history.append((user_input, None))   # 在历史记录中添加用户输入，并用 None 占位，Gradio 会将 None 视作正在生成。\n",
    "    yield history\n",
    "    full_response = \"\"\n",
    "    async for chunk in chain.astream({\"messages\": messages}):\n",
    "        full_response += chunk\n",
    "        history[-1] = (user_input, full_response)\n",
    "        yield history\n",
    "\n",
    "# 创建Gradio界面\n",
    "with gr.Blocks(title=\"多轮对话聊天机器人\") as demo:\n",
    "    gr.Markdown(\"与AI进行多轮对话，它会记住之前的对话内容，支持流式输出\")\n",
    "\n",
    "    chatbot = gr.Chatbot(\n",
    "        label=\"对话记录\",\n",
    "        bubble_full_width=False,\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        user_input = gr.Textbox(\n",
    "            label=\"输入消息\",\n",
    "            placeholder=\"请输入您的问题...\",\n",
    "            container=False,\n",
    "            scale=9\n",
    "        )\n",
    "        send_btn = gr.Button(\"发送\", variant=\"primary\", scale=1)\n",
    "\n",
    "    with gr.Row():\n",
    "        clear_btn = gr.Button(\"清空对话\")\n",
    "        examples = gr.Examples(\n",
    "            examples=[\"你好\", \"请介绍一下你自己\", \"你能帮我做什么？\"],\n",
    "            inputs=user_input\n",
    "        )\n",
    "    \n",
    "    # 绑定事件\n",
    "    user_input.submit(\n",
    "        fn=chat_stream,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[chatbot],\n",
    "        queue=True\n",
    "    ).then(\n",
    "        lambda: \"\",\n",
    "        None,\n",
    "        user_input\n",
    "    )\n",
    "\n",
    "    send_btn.click(\n",
    "        fn=chat_stream,\n",
    "        inputs=[user_input, chatbot],\n",
    "        outputs=[chatbot],\n",
    "        queue=True\n",
    "    ).then(\n",
    "        lambda: \"\",\n",
    "        None,\n",
    "        user_input\n",
    "    )\n",
    "\n",
    "    clear_btn.click(\n",
    "        fn=lambda: ([], None),\n",
    "        inputs=None,\n",
    "        outputs=[chatbot, user_input]\n",
    "    )\n",
    "\n",
    "def find_free_port():\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        s.bind(('', 0))\n",
    "        s.listen(1)\n",
    "        port = s.getsockname()[1]\n",
    "    return port\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    port = find_free_port()\n",
    "    print(f\"使用端口：{port}\")\n",
    "    demo.queue()\n",
    "    demo.launch(\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=port,\n",
    "        share=True,\n",
    "        inbrowser=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f100cdf7",
   "metadata": {},
   "source": [
    "## 企业财务造假识别Agent基础框架\n",
    "```mermaid\n",
    "    graph TB;\n",
    "        A[用户输入：公司名称、行业] --> B{主控Agent启动};\n",
    "        \n",
    "        subgraph \"核心部分\"\n",
    "            B -- 获取公司数据 --> C(get_company_financials);\n",
    "            C -- 返回并整合公司财报/信息 --> D{模型思考并提取关键指标};\n",
    "            D -- 调用工具 --> E[extract_key_indicators];\n",
    "            E -- 返回定制指标列表 --> F{模型思考并计算指标};\n",
    "            F -- 调用工具 --> G[calculate_financial_ratios];\n",
    "            G -- 返回计算结果 --> H{模型识别异常模式};\n",
    "            H -- 调用工具 --> I[detect_anomaly_with_logic_rules];\n",
    "            I -- 返回异常列表 --> J{模型推理异常原因};\n",
    "            J -- 对每个异常调用工具 --> K[reason_for_anomaly];\n",
    "            K -- 返回详细解释 --> L{整合所有信息};\n",
    "        end\n",
    "        \n",
    "        L -- 报告生成 --> M[主控Agent生成最终报告];\n",
    "        M --> N[向用户输出];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7b8d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"coord\": {\"lon\": 116.3972, \"lat\": 39.9075}, \"weather\": [{\"id\": 800, \"main\": \"Clear\", \"description\": \"\\\\u6674\", \"icon\": \"01d\"}], \"base\": \"stations\", \"main\": {\"temp\": 31.94, \"feels_like\": 34.02, \"temp_min\": 31.94, \"temp_max\": 31.94, \"pressure\": 1001, \"humidity\": 49, \"sea_level\": 1001, \"grnd_level\": 995}, \"visibility\": 10000, \"wind\": {\"speed\": 4.48, \"deg\": 196, \"gust\": 6.69}, \"clouds\": {\"all\": 0}, \"dt\": 1754903754, \"sys\": {\"type\": 1, \"id\": 9609, \"country\": \"CN\", \"sunrise\": 1754860929, \"sunset\": 1754911038}, \"timezone\": 28800, \"id\": 1816670, \"name\": \"Beijing\", \"cod\": 200}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "def get_weather(loc):\n",
    "    url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "    params = {\n",
    "        \"q\":loc,\n",
    "        \"appid\":\"bc4c354ab9e1d1e46dcadf6913ecd5ca\",\n",
    "        \"units\":\"metric\",\n",
    "        \"lang\":\"zh_cn\"\n",
    "    }\n",
    "    response = requests.get(url,params=params)\n",
    "    data = response.json() \n",
    "    return json.dumps(data)  \n",
    "get_weather(\"Beijing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b15ce6",
   "metadata": {},
   "source": [
    "创建天气预警Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e4949e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m关于广州、北京、上海哪个城市更热的问题，需要结合实时天气数据和气候特点来综合分析。以下是具体对比：\n",
      "\n",
      "1. **当前实时温度（2025年8月11日）**\n",
      "   - **上海**：当天最高气温达37℃，全天温差较小（27℃~35℃），且未来多日持续维持在35℃左右的高温状态，伴有“酷热难耐”的提示；\n",
      "   - **广州**：今日气温为26℃~35℃，当前温度32℃，同样发布防暑预警，但夜间降温幅度有限，闷热感显著；\n",
      "   - **北京**：今日最高温34℃，全天范围24℃~33℃，虽炎热但昼夜温差相对较大，午后需避免户外活动。\n",
      "\n",
      "2. **体感差异与气候特征**\n",
      "   - **上海**属于典型的湿热型气候，受海洋影响较大，昼夜温差小（约10度以内），空气湿度高，导致汗水不易蒸发，形成黏腻的闷热感。尤其在无风时段，室内外均需依赖空调调节；\n",
      "   - **广州**地处北回归线附近，夏季太阳直射强烈，地面辐射升温快，曾测得极端地表温度超58℃。其特点是白天高温持续时间长、早晚降温不明显，叠加高湿度后形成全天候的蒸笼效应；\n",
      "   - **北京**则为干热型气候，阳光直射下体感炙烤，但树荫或建筑阴影处可明显感到凉爽。雷阵雨频繁短暂缓解闷热，不过降雨后湿度上升会加剧桑拿天体验。\n",
      "\n",
      "3. **长期趋势与主观感受**\n",
      "   - 从历史经验看，广州在7-9月的整体热度通常高于上海，因纬度更低且城市热岛效应集中（如天河、海珠等核心区域高楼密集、绿化不足）。而上海因地域广阔、沿海风力调节等因素，极端高温天数相对较少；\n",
      "   - 北京夏季虽短（6月下旬至8月下旬），但绝对高温峰值突出，且干燥空气加速水分流失，易造成脱水风险。部分人认为其暴晒型炎热比南方的闷热更难适应。\n",
      "\n",
      "综上所述，若以即时数据为准，上海当前最热（37℃）；但从体感舒适度和持续影响来看，广州的湿热与全天候高温可能更令人煎熬。北京则因干热特性，在遮阳条件下实际耐受度略高。不同个体对湿度、日照的敏感度差异会影响主观判断，建议根据出行时段和个人适应性选择防护措施。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '广州、北京、上海相比，哪一个更热？', 'output': '关于广州、北京、上海哪个城市更热的问题，需要结合实时天气数据和气候特点来综合分析。以下是具体对比：\\n\\n1. **当前实时温度（2025年8月11日）**\\n   - **上海**：当天最高气温达37℃，全天温差较小（27℃~35℃），且未来多日持续维持在35℃左右的高温状态，伴有“酷热难耐”的提示；\\n   - **广州**：今日气温为26℃~35℃，当前温度32℃，同样发布防暑预警，但夜间降温幅度有限，闷热感显著；\\n   - **北京**：今日最高温34℃，全天范围24℃~33℃，虽炎热但昼夜温差相对较大，午后需避免户外活动。\\n\\n2. **体感差异与气候特征**\\n   - **上海**属于典型的湿热型气候，受海洋影响较大，昼夜温差小（约10度以内），空气湿度高，导致汗水不易蒸发，形成黏腻的闷热感。尤其在无风时段，室内外均需依赖空调调节；\\n   - **广州**地处北回归线附近，夏季太阳直射强烈，地面辐射升温快，曾测得极端地表温度超58℃。其特点是白天高温持续时间长、早晚降温不明显，叠加高湿度后形成全天候的蒸笼效应；\\n   - **北京**则为干热型气候，阳光直射下体感炙烤，但树荫或建筑阴影处可明显感到凉爽。雷阵雨频繁短暂缓解闷热，不过降雨后湿度上升会加剧桑拿天体验。\\n\\n3. **长期趋势与主观感受**\\n   - 从历史经验看，广州在7-9月的整体热度通常高于上海，因纬度更低且城市热岛效应集中（如天河、海珠等核心区域高楼密集、绿化不足）。而上海因地域广阔、沿海风力调节等因素，极端高温天数相对较少；\\n   - 北京夏季虽短（6月下旬至8月下旬），但绝对高温峰值突出，且干燥空气加速水分流失，易造成脱水风险。部分人认为其暴晒型炎热比南方的闷热更难适应。\\n\\n综上所述，若以即时数据为准，上海当前最热（37℃）；但从体感舒适度和持续影响来看，广州的湿热与全天候高温可能更令人煎熬。北京则因干热特性，在遮阳条件下实际耐受度略高。不同个体对湿度、日照的敏感度差异会影响主观判断，建议根据出行时段和个人适应性选择防护措施。'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from langchain.agents import initialize_agent, AgentType, tool\n",
    "from langchain_community.chat_models import ChatSparkLLM\n",
    "\n",
    "spark_config = {\n",
    "    \"spark_app_id\": \"63b7eade\",\n",
    "    \"spark_api_key\": \"6f088336dc8dd45b737b0deb2a697887\",\n",
    "    \"spark_api_secret\": \"N2FiZmE3Y2U1YzlhOGZkMWEwM2RhMjMz\",\n",
    "    \"spark_api_url\": \"wss://spark-api.xf-yun.com/v4.0/chat\",\n",
    "    \"spark_llm_domain\": \"4.0Ultra\"\n",
    "}\n",
    "model = ChatSparkLLM(**spark_config)\n",
    "@tool\n",
    "def get_weather(location: str) -> str:\n",
    "    \"\"\"查询指定城市的天气信息。\"\"\"\n",
    "    try:\n",
    "        url = \"https://api.openweathermap.org/data/2.5/weather\"\n",
    "        params = {\n",
    "            \"q\": location,\n",
    "            \"appid\": \"bc4c354ab9e1d1e46dcadf6913ecd5ca\",\n",
    "            \"units\": \"metric\",\n",
    "            \"lang\": \"zh_cn\"\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return json.dumps(data, ensure_ascii=False)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)}, ensure_ascii=False)\n",
    "    \n",
    "tools = [get_weather]\n",
    "# Use initialize_agent with AgentType.OPENAI_FUNCTIONS for robust function calling.\n",
    "agent_executor = initialize_agent(\n",
    "    tools, \n",
    "    model, \n",
    "    agent=AgentType.OPENAI_FUNCTIONS, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True \n",
    ")\n",
    "response = agent_executor.invoke({\n",
    "    \"input\": \"广州、北京、上海相比，哪一个更热？\",\n",
    "})\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
